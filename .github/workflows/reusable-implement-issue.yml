name: Reusable Claude Implement Issue

on:
  workflow_call:
    inputs:
      issue_number:
        description: 'Issue number (for workflow_dispatch trigger)'
        required: false
        type: number
      num_implementations:
        description: 'Number of parallel implementations'
        required: false
        type: number
        default: 3
      claude_model:
        description: 'Claude model to use'
        required: false
        type: string
        default: 'claude-opus-4-5-20251101'
      prompts_repo:
        description: 'Repository for prompts and agents'
        required: false
        type: string
        default: 'mkrueger12/claude-parallel'
      prompts_ref:
        description: 'Git ref for prompts repository'
        required: false
        type: string
        default: 'main'
      bot_name:
        description: 'Git author name for commits'
        required: false
        type: string
        default: 'Claude Parallel Bot'
      bot_email:
        description: 'Git author email for commits'
        required: false
        type: string
        default: 'bot@claude-parallel.dev'
      dry_run:
        description: 'Skip Claude, use mock responses'
        required: false
        type: boolean
        default: false
      event_name:
        description: 'The github.event_name from caller'
        required: false
        type: string
        default: 'workflow_dispatch'
      event_issue_number:
        description: 'The github.event.issue.number from caller'
        required: false
        type: string
        default: ''
    secrets:
      CLAUDE_CODE_OAUTH_TOKEN:
        required: false
      ANTHROPIC_API_KEY:
        required: false
      GH_PAT:
        required: true

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.generate.outputs.matrix }}
    steps:
      - name: Validate authentication
        if: ${{ inputs.dry_run != true }}
        run: |
          if [[ -z "${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}" ]] && [[ -z "${{ secrets.ANTHROPIC_API_KEY }}" ]]; then
            echo "Error: At least one authentication method must be provided"
            echo "Please provide either CLAUDE_CODE_OAUTH_TOKEN or ANTHROPIC_API_KEY"
            exit 1
          fi

      - name: Generate matrix
        id: generate
        run: |
          # Generate array [1, 2, ..., num_implementations]
          MATRIX=$(seq 1 ${{ inputs.num_implementations }} | jq -s -c '.')
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT
          echo "Generated matrix: $MATRIX"

  implement:
    needs: generate-matrix
    runs-on: ubuntu-latest
    strategy:
      matrix:
        impl: ${{ fromJSON(needs.generate-matrix.outputs.matrix) }}
      fail-fast: false

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GH_PAT }}

      - name: Get issue details
        id: issue
        uses: mkrueger12/claude-parallel/.github/actions/get-issue-details@main
        with:
          issue_number: ${{ inputs.issue_number }}
          github_token: ${{ secrets.GH_PAT }}
          event_name: ${{ inputs.event_name }}
          event_issue_number: ${{ inputs.event_issue_number }}

      - name: Create implementation branch
        run: |
          BRANCH="impl-${{ github.run_id }}-${{ matrix.impl }}"
          git checkout -b "$BRANCH"
          echo "BRANCH=$BRANCH" >> $GITHUB_ENV

      - name: Setup Claude CLI
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/setup-claude@main
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}

      - name: Fetch custom agents
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/fetch-agents@main
        with:
          repo: ${{ inputs.prompts_repo }}
          ref: ${{ inputs.prompts_ref }}

      - name: Detect runtime
        id: runtime
        uses: mkrueger12/claude-parallel/.github/actions/detect-runtime@main

      - name: Setup Bun
        if: steps.runtime.outputs.runtime == 'js' && steps.runtime.outputs.package_manager == 'bun'
        uses: oven-sh/setup-bun@v2

      - name: Setup Node.js
        if: steps.runtime.outputs.runtime == 'js' && steps.runtime.outputs.package_manager != 'bun'
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Setup Python
        if: steps.runtime.outputs.runtime == 'python'
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Setup Go
        if: steps.runtime.outputs.runtime == 'go'
        uses: actions/setup-go@v5
        with:
          go-version: '1.21'

      - name: Setup Rust
        if: steps.runtime.outputs.runtime == 'rust'
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Install dependencies
        run: |
          case "${{ steps.runtime.outputs.runtime }}" in
            js)
              if [ -f "package.json" ]; then
                case "${{ steps.runtime.outputs.package_manager }}" in
                  bun) bun install ;;
                  pnpm) npm install -g pnpm && pnpm install ;;
                  yarn) yarn install ;;
                  npm) npm install ;;
                esac
              fi
              ;;
            python)
              if [ -f "requirements.txt" ]; then
                pip install -r requirements.txt
              elif [ -f "pyproject.toml" ]; then
                if [ "${{ steps.runtime.outputs.package_manager }}" = "poetry" ]; then
                  pip install poetry && poetry install
                else
                  pip install .
                fi
              fi
              ;;
            go)
              if [ -f "go.mod" ]; then
                go mod download
              fi
              ;;
            rust)
              if [ -f "Cargo.toml" ]; then
                cargo fetch
              fi
              ;;
          esac

      - name: Fetch implementation prompt
        if: ${{ inputs.dry_run != true }}
        run: |
          curl -fsSL "https://raw.githubusercontent.com/${{ inputs.prompts_repo }}/${{ inputs.prompts_ref }}/.github/prompts/implementation.md" \
            -o /tmp/implementation-template.md

      - name: Run implementation
        if: ${{ inputs.dry_run != true }}
        run: |
          export PATH="$HOME/.local/bin:$PATH"

          # Build feature request file
          echo "${{ steps.issue.outputs.title }}" > /tmp/feature_request.txt
          echo "" >> /tmp/feature_request.txt
          cat ${{ steps.issue.outputs.body_file }} >> /tmp/feature_request.txt

          # Substitute using awk (handles multiline)
          awk '
            BEGIN {
              while ((getline line < "/tmp/feature_request.txt") > 0) {
                feature = feature (feature ? "\n" : "") line
              }
            }
            { gsub(/\{\{FEATURE_REQUEST\}\}/, feature); print }
          ' /tmp/implementation-template.md > /tmp/prompt.md

          echo "Starting implementation ${{ matrix.impl }}..."
          echo "Prompt size: $(wc -c < /tmp/prompt.md) bytes"

          # Run claude and capture exit code
          set +e
          claude --print "$(cat /tmp/prompt.md)" \
            --output-format json \
            --model ${{ inputs.claude_model }} \
            --dangerously-skip-permissions \
            > result.json 2>&1
          CLAUDE_EXIT=$?
          set -e

          echo "Claude exit code: $CLAUDE_EXIT"

          # Check if we got valid output
          if [ -s result.json ] && jq -e . result.json > /dev/null 2>&1; then
            echo "Implementation completed successfully"
          else
            echo "::error::Implementation ${{ matrix.impl }} failed"
            echo "=== Claude exit code: $CLAUDE_EXIT ==="
            echo "=== result.json contents (first 500 chars): ==="
            head -c 500 result.json 2>/dev/null || echo "(empty or missing)"
            echo ""
            echo "=== Checking claude installation: ==="
            which claude || echo "claude not found in PATH"
            echo "PATH: $PATH"
            exit 1
          fi

      - name: Mock implementation (dry run)
        if: ${{ inputs.dry_run == true }}
        run: |
          # Create mock result
          echo '{"result": "Mock implementation ${{ matrix.impl }} completed"}' > result.json

          # Create a mock change to test the workflow
          echo "# Mock Implementation ${{ matrix.impl }}" >> MOCK_CHANGES.md
          echo "" >> MOCK_CHANGES.md
          echo "Issue: ${{ steps.issue.outputs.title }}" >> MOCK_CHANGES.md
          echo "Run ID: ${{ github.run_id }}" >> MOCK_CHANGES.md
          echo "Timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> MOCK_CHANGES.md

      - name: Commit changes
        run: |
          git config user.name "${{ inputs.bot_name }}"
          git config user.email "${{ inputs.bot_email }}"

          # Add all changes
          git add -A

          if git diff --staged --quiet; then
            echo "No changes to commit"
            echo "HAS_CHANGES=false" >> $GITHUB_ENV
          else
            git commit -m "Implementation ${{ matrix.impl }}: ${{ steps.issue.outputs.title }}"
            echo "HAS_CHANGES=true" >> $GITHUB_ENV
          fi

      - name: Push branch
        if: env.HAS_CHANGES == 'true'
        run: |
          git push origin "$BRANCH"

      - name: Upload result
        uses: actions/upload-artifact@v4
        with:
          name: impl-${{ matrix.impl }}
          path: |
            result.json
            error.log
          retention-days: 1

  review:
    needs: [generate-matrix, implement]
    if: always() && !cancelled()
    runs-on: ubuntu-latest
    outputs:
      winning_branch: ${{ steps.create_pr.outputs.winning_branch }}
      pr_number: ${{ steps.create_pr.outputs.pr_number }}
      issue_number: ${{ steps.issue.outputs.number }}
      issue_title: ${{ steps.issue.outputs.title }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GH_PAT }}

      - name: Get issue details
        id: issue
        uses: mkrueger12/claude-parallel/.github/actions/get-issue-details@main
        with:
          issue_number: ${{ inputs.issue_number }}
          github_token: ${{ secrets.GH_PAT }}
          event_name: ${{ inputs.event_name }}
          event_issue_number: ${{ inputs.event_issue_number }}

      - name: Download all implementation results
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Fetch implementation branches
        run: |
          mkdir -p worktrees
          for i in $(echo '${{ needs.generate-matrix.outputs.matrix }}' | jq -r '.[]'); do
            BRANCH="impl-${{ github.run_id }}-$i"
            if git fetch origin "$BRANCH" 2>/dev/null; then
              git worktree add "worktrees/impl-$i" "origin/$BRANCH"
              echo "Fetched impl-$i"
            else
              echo "Branch $BRANCH not found (implementation may have failed)"
            fi
          done

      - name: Setup Claude CLI
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/setup-claude@main
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}

      - name: Fetch custom agents
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/fetch-agents@main
        with:
          repo: ${{ inputs.prompts_repo }}
          ref: ${{ inputs.prompts_ref }}

      - name: Fetch review prompt
        if: ${{ inputs.dry_run != true }}
        run: |
          curl -fsSL "https://raw.githubusercontent.com/${{ inputs.prompts_repo }}/${{ inputs.prompts_ref }}/.github/prompts/review.md" \
            -o /tmp/review-template.md

      - name: Review implementations
        if: ${{ inputs.dry_run != true }}
        run: |
          export PATH="$HOME/.local/bin:$PATH"

          # Build feature request file
          echo "${{ steps.issue.outputs.title }}" > /tmp/feature_request.txt
          echo "" >> /tmp/feature_request.txt
          cat ${{ steps.issue.outputs.body_file }} >> /tmp/feature_request.txt

          # Substitute using awk (handles multiline)
          awk '
            BEGIN {
              while ((getline line < "/tmp/feature_request.txt") > 0) {
                feature = feature (feature ? "\n" : "") line
              }
            }
            {
              gsub(/\{\{FEATURE_REQUEST\}\}/, feature)
              gsub(/\{\{WORKTREES_DIR\}\}/, "worktrees")
              gsub(/\{\{NUM_IMPLEMENTATIONS\}\}/, "${{ inputs.num_implementations }}")
              print
            }
          ' /tmp/review-template.md > /tmp/review-prompt.md

          echo "Starting review..."

          # Define JSON schema for structured output
          JSON_SCHEMA='{"type":"object","properties":{"best":{"type":"integer","minimum":1,"maximum":${{ inputs.num_implementations }}},"reasoning":{"type":"string"}},"required":["best","reasoning"]}'

          claude --print "$(cat /tmp/review-prompt.md)" \
            --output-format json \
            --json-schema "$JSON_SCHEMA" \
            --model ${{ inputs.claude_model }} \
            --dangerously-skip-permissions \
            > review-result.json 2> review-error.log || true

          cat review-result.json

      - name: Mock review (dry run)
        if: ${{ inputs.dry_run == true }}
        run: |
          # Pick a random winner (1-num_implementations) for testing
          MAX=${{ inputs.num_implementations }}
          WINNER=$(( (RANDOM % MAX) + 1 ))
          echo "Mock review selecting implementation $WINNER"

          # Cycle through different response formats to test all parsing strategies
          # This ensures the parser is exercised with different formats across dry runs
          FORMAT_SELECTOR=$(( ${{ github.run_id }} % 3 ))

          case $FORMAT_SELECTOR in
            0)
              # Format 1: structured_output field (primary --json-schema format)
              echo "Testing parsing Strategy 1: structured_output format"
              echo "{\"type\":\"result\",\"result\":\"\",\"structured_output\":{\"best\":$WINNER,\"reasoning\":\"Dry run mock - testing structured_output parsing\"}}" > review-result.json
              ;;
            1)
              # Format 2: Direct root-level JSON (tests Strategy 3)
              echo "Testing parsing Strategy 3: root-level JSON format"
              echo "{\"best\":$WINNER,\"reasoning\":\"Dry run mock - testing root-level JSON parsing\"}" > review-result.json
              ;;
            2)
              # Format 3: JSON embedded in result string (tests Strategy 2)
              echo "Testing parsing Strategy 2: result field as JSON string"
              # The result field contains a JSON string that needs parsing
              echo "{\"type\":\"result\",\"result\":\"{\\\"best\\\":$WINNER,\\\"reasoning\\\":\\\"Dry run mock - testing result field parsing\\\"}\"}" > review-result.json
              ;;
          esac

          echo "=== Mock review-result.json (format $FORMAT_SELECTOR): ==="
          cat review-result.json

      - name: Parse review and create PR
        id: create_pr
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          # Extract the decision from Claude's response
          # With --json-schema, the result should be valid JSON directly
          echo "=== Parsing review result ==="
          echo "=== Raw review-result.json contents: ==="
          cat review-result.json
          echo ""
          echo "=== End raw contents ==="

          # Check for Claude CLI errors (rate limits, auth issues, etc.)
          if jq -e '.is_error == true' review-result.json >/dev/null 2>&1; then
            ERROR_MSG=$(jq -r '.result // "Unknown error"' review-result.json)
            echo ""
            echo "::error::Claude CLI returned an error: $ERROR_MSG"
            echo ""
            echo "This is NOT a parsing issue - Claude failed to generate a response."
            echo "Common causes:"
            echo "  - Rate limit exceeded (wait for reset time shown above)"
            echo "  - Authentication issues (check CLAUDE_CODE_OAUTH_TOKEN secret)"
            echo "  - API outage"
            exit 1
          fi

          # The output format wraps response in {"result": "..."} where result is JSON string
          # Try multiple extraction paths for robustness
          DECISION_JSON=""
          STRATEGIES_TRIED=""

          # Strategy 1: Check for structured_output field (primary method with --json-schema)
          echo "Trying Strategy 1: .structured_output field..."
          STRUCTURED_OUTPUT=$(jq -c '.structured_output' review-result.json 2>/dev/null || echo "null")
          echo "  .structured_output = $STRUCTURED_OUTPUT"
          if [ "$STRUCTURED_OUTPUT" != "null" ] && [ -n "$STRUCTURED_OUTPUT" ]; then
            # Verify it has the 'best' field
            if echo "$STRUCTURED_OUTPUT" | jq -e '.best' >/dev/null 2>&1; then
              DECISION_JSON="$STRUCTURED_OUTPUT"
              echo "  ✓ Found valid decision in .structured_output"
            else
              echo "  ✗ .structured_output exists but missing 'best' field"
              STRATEGIES_TRIED="$STRATEGIES_TRIED\n- Strategy 1: .structured_output exists but missing 'best' field (value: $STRUCTURED_OUTPUT)"
            fi
          else
            STRATEGIES_TRIED="$STRATEGIES_TRIED\n- Strategy 1: .structured_output is null or empty"
          fi

          # Strategy 2: With --json-schema, result field should contain JSON string - parse it
          if [ -z "$DECISION_JSON" ]; then
            echo "Trying Strategy 2: .result field as JSON string..."
            RESULT_FIELD=$(jq -r '.result // empty' review-result.json 2>/dev/null)
            echo "  .result = ${RESULT_FIELD:0:200}..."
            if [ -n "$RESULT_FIELD" ]; then
              # Parse result field as JSON and check if it has .best
              if echo "$RESULT_FIELD" | jq -e '.best' >/dev/null 2>&1; then
                DECISION_JSON=$(echo "$RESULT_FIELD" | jq -c '.')
                echo "  ✓ Found valid decision in .result"
              else
                STRATEGIES_TRIED="$STRATEGIES_TRIED\n- Strategy 2: .result exists but is not JSON with 'best' field"
              fi
            else
              STRATEGIES_TRIED="$STRATEGIES_TRIED\n- Strategy 2: .result is empty"
            fi
          fi

          # Strategy 3: Check if the file itself is the decision JSON (direct output)
          if [ -z "$DECISION_JSON" ]; then
            echo "Trying Strategy 3: root-level JSON with 'best' field..."
            if jq -e '.best' review-result.json >/dev/null 2>&1; then
              DECISION_JSON=$(jq -c '.' review-result.json)
              echo "  ✓ Found valid decision at root level"
            else
              STRATEGIES_TRIED="$STRATEGIES_TRIED\n- Strategy 3: root JSON does not have 'best' field"
            fi
          fi

          # Strategy 4: Fallback - extract from text content (handles non-schema responses)
          if [ -z "$DECISION_JSON" ]; then
            echo "Trying Strategy 4: regex extraction from text content..."
            RESULT=$(jq -r '.result // .content[0].text // .text // .' review-result.json 2>/dev/null || cat review-result.json)
            # Use grep with perl regex to extract JSON with "best" field
            REGEX_MATCH=$(echo "$RESULT" | grep -oP '\{[^{}]*"best"\s*:\s*\d+[^{}]*\}' | head -1 || true)
            if [ -n "$REGEX_MATCH" ]; then
              DECISION_JSON="$REGEX_MATCH"
              echo "  ✓ Found decision via regex extraction"
            else
              STRATEGIES_TRIED="$STRATEGIES_TRIED\n- Strategy 4: no JSON with 'best' field found in text content"
            fi
          fi

          if [ -z "$DECISION_JSON" ]; then
            echo ""
            echo "::error::Could not find decision JSON in review output after trying all strategies"
            echo ""
            echo "=== Strategies attempted: ===$STRATEGIES_TRIED"
            echo ""
            echo "=== Debug info ==="
            echo "File size: $(wc -c < review-result.json) bytes"
            echo "Is valid JSON: $(jq -e . review-result.json >/dev/null 2>&1 && echo 'yes' || echo 'no')"
            echo "Top-level keys: $(jq -r 'keys | join(", ")' review-result.json 2>/dev/null || echo 'N/A')"
            echo ""
            echo "Expected format (with --json-schema):"
            echo '  {"type":"result","result":"","structured_output":{"best":N,"reasoning":"..."}}'
            echo ""
            echo "=== Last 50 lines of review-result.json: ==="
            tail -50 review-result.json
            exit 1
          fi

          echo ""
          echo "=== Successfully extracted decision ==="
          echo "DECISION_JSON: $DECISION_JSON"

          # Parse the extracted JSON
          BEST=$(echo "$DECISION_JSON" | jq -r '.best // empty')

          if [ -z "$BEST" ]; then
            echo "::error::Could not parse 'best' from decision JSON"
            exit 1
          fi

          REASONING=$(echo "$DECISION_JSON" | jq -r '.reasoning // "No reasoning provided"')

          echo "Selected implementation: $BEST"

          WINNING_BRANCH="impl-${{ github.run_id }}-$BEST"
          echo "winning_branch=$WINNING_BRANCH" >> $GITHUB_OUTPUT

          # Create PR
          PR_BODY="## AI-Generated Implementation (Best of ${{ inputs.num_implementations }})

          **Issue:** #${{ steps.issue.outputs.number }}
          **Selected:** Implementation $BEST

          ### Reasoning
          $REASONING

          ---
          *Generated by Claude Parallel workflow*"

          PR_URL=$(gh pr create \
            --head "$WINNING_BRANCH" \
            --title "Feature: ${{ steps.issue.outputs.title }}" \
            --body "$PR_BODY" \
            --draft)

          # Extract PR number from URL
          PR_NUMBER=$(echo "$PR_URL" | grep -oE '[0-9]+$')
          echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
          echo "Created PR #$PR_NUMBER"

      - name: Cleanup losing branches
        if: always() && steps.create_pr.outputs.winning_branch != ''
        run: |
          WINNING="${{ steps.create_pr.outputs.winning_branch }}"
          # Extract impl number (last character after final dash)
          BEST="${WINNING##*-}"

          for i in $(echo '${{ needs.generate-matrix.outputs.matrix }}' | jq -r '.[]'); do
            if [ "$i" != "$BEST" ]; then
              BRANCH="impl-${{ github.run_id }}-$i"
              git push origin --delete "$BRANCH" 2>/dev/null || true
            fi
          done

  verify:
    needs: review
    if: needs.review.outputs.pr_number != ''
    runs-on: ubuntu-latest

    steps:
      - name: Checkout winning branch
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.review.outputs.winning_branch }}
          fetch-depth: 0
          token: ${{ secrets.GH_PAT }}

      - name: Setup Claude CLI
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/setup-claude@main
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}

      - name: Fetch custom agents
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/fetch-agents@main
        with:
          repo: ${{ inputs.prompts_repo }}
          ref: ${{ inputs.prompts_ref }}

      - name: Detect runtime
        id: runtime
        uses: mkrueger12/claude-parallel/.github/actions/detect-runtime@main

      - name: Setup Bun
        if: steps.runtime.outputs.runtime == 'js' && steps.runtime.outputs.package_manager == 'bun'
        uses: oven-sh/setup-bun@v2

      - name: Setup Node.js
        if: steps.runtime.outputs.runtime == 'js' && steps.runtime.outputs.package_manager != 'bun'
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Setup Python
        if: steps.runtime.outputs.runtime == 'python'
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Setup Go
        if: steps.runtime.outputs.runtime == 'go'
        uses: actions/setup-go@v5
        with:
          go-version: '1.21'

      - name: Setup Rust
        if: steps.runtime.outputs.runtime == 'rust'
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Install dependencies
        run: |
          case "${{ steps.runtime.outputs.runtime }}" in
            js)
              if [ -f "package.json" ]; then
                case "${{ steps.runtime.outputs.package_manager }}" in
                  bun) bun install ;;
                  pnpm) npm install -g pnpm && pnpm install ;;
                  yarn) yarn install ;;
                  npm) npm install ;;
                esac
              fi
              ;;
            python)
              if [ -f "requirements.txt" ]; then
                pip install -r requirements.txt
              elif [ -f "pyproject.toml" ]; then
                if [ "${{ steps.runtime.outputs.package_manager }}" = "poetry" ]; then
                  pip install poetry && poetry install
                else
                  pip install .
                fi
              fi
              ;;
            go)
              if [ -f "go.mod" ]; then
                go mod download
              fi
              ;;
            rust)
              if [ -f "Cargo.toml" ]; then
                cargo fetch
              fi
              ;;
          esac

      - name: Run build checks
        id: build_checks
        run: |
          mkdir -p /tmp/build-results

          # Initialize statuses
          BUILD_STATUS="skip"
          TESTS_STATUS="skip"
          LINT_STATUS="skip"
          TYPECHECK_STATUS="skip"

          # Run build
          echo "=== Running build ===" > /tmp/build-results/build.txt
          case "${{ steps.runtime.outputs.runtime }}" in
            js)
              if [ -f "package.json" ] && grep -q '"build"' package.json; then
                if ${{ steps.runtime.outputs.package_manager }} run build >> /tmp/build-results/build.txt 2>&1; then
                  BUILD_STATUS="pass"
                else
                  BUILD_STATUS="fail"
                fi
              else
                echo "No build script found" >> /tmp/build-results/build.txt
              fi
              ;;
            python)
              if [ -f "setup.py" ] || ([ -f "pyproject.toml" ] && grep -q '\[build-system\]' pyproject.toml); then
                if python -m build >> /tmp/build-results/build.txt 2>&1; then
                  BUILD_STATUS="pass"
                else
                  BUILD_STATUS="fail"
                fi
              else
                echo "No build system found" >> /tmp/build-results/build.txt
              fi
              ;;
            go)
              if go build ./... >> /tmp/build-results/build.txt 2>&1; then
                BUILD_STATUS="pass"
              else
                BUILD_STATUS="fail"
              fi
              ;;
            rust)
              if cargo build >> /tmp/build-results/build.txt 2>&1; then
                BUILD_STATUS="pass"
              else
                BUILD_STATUS="fail"
              fi
              ;;
          esac
          echo "BUILD_STATUS=$BUILD_STATUS" >> $GITHUB_OUTPUT

          # Run tests
          echo "=== Running tests ===" > /tmp/build-results/tests.txt
          case "${{ steps.runtime.outputs.runtime }}" in
            js)
              if [ -f "package.json" ] && grep -q '"test"' package.json; then
                if ${{ steps.runtime.outputs.package_manager }} test >> /tmp/build-results/tests.txt 2>&1; then
                  TESTS_STATUS="pass"
                else
                  TESTS_STATUS="fail"
                fi
              else
                echo "No test script found" >> /tmp/build-results/tests.txt
              fi
              ;;
            python)
              if command -v pytest >/dev/null 2>&1; then
                if pytest >> /tmp/build-results/tests.txt 2>&1; then
                  TESTS_STATUS="pass"
                else
                  TESTS_STATUS="fail"
                fi
              else
                echo "pytest not found" >> /tmp/build-results/tests.txt
              fi
              ;;
            go)
              if go test ./... >> /tmp/build-results/tests.txt 2>&1; then
                TESTS_STATUS="pass"
              else
                TESTS_STATUS="fail"
              fi
              ;;
            rust)
              if cargo test >> /tmp/build-results/tests.txt 2>&1; then
                TESTS_STATUS="pass"
              else
                TESTS_STATUS="fail"
              fi
              ;;
          esac
          echo "TESTS_STATUS=$TESTS_STATUS" >> $GITHUB_OUTPUT

          # Run lint
          echo "=== Running lint ===" > /tmp/build-results/lint.txt
          case "${{ steps.runtime.outputs.runtime }}" in
            js)
              if [ -f "package.json" ] && grep -q '"lint"' package.json; then
                if ${{ steps.runtime.outputs.package_manager }} run lint >> /tmp/build-results/lint.txt 2>&1; then
                  LINT_STATUS="pass"
                else
                  LINT_STATUS="fail"
                fi
              else
                echo "No lint script found" >> /tmp/build-results/lint.txt
              fi
              ;;
            python)
              if command -v ruff >/dev/null 2>&1; then
                if ruff check . >> /tmp/build-results/lint.txt 2>&1; then
                  LINT_STATUS="pass"
                else
                  LINT_STATUS="fail"
                fi
              else
                echo "ruff not found" >> /tmp/build-results/lint.txt
              fi
              ;;
            go)
              if command -v golint >/dev/null 2>&1; then
                if golint ./... >> /tmp/build-results/lint.txt 2>&1; then
                  LINT_STATUS="pass"
                else
                  LINT_STATUS="fail"
                fi
              else
                echo "golint not found" >> /tmp/build-results/lint.txt
              fi
              ;;
            rust)
              if cargo clippy >> /tmp/build-results/lint.txt 2>&1; then
                LINT_STATUS="pass"
              else
                LINT_STATUS="fail"
              fi
              ;;
          esac
          echo "LINT_STATUS=$LINT_STATUS" >> $GITHUB_OUTPUT

          # Run typecheck
          echo "=== Running typecheck ===" > /tmp/build-results/typecheck.txt
          case "${{ steps.runtime.outputs.runtime }}" in
            js)
              if [ -f "tsconfig.json" ]; then
                if npx tsc --noEmit >> /tmp/build-results/typecheck.txt 2>&1; then
                  TYPECHECK_STATUS="pass"
                else
                  TYPECHECK_STATUS="fail"
                fi
              else
                echo "No tsconfig.json found" >> /tmp/build-results/typecheck.txt
              fi
              ;;
            python)
              if command -v mypy >/dev/null 2>&1; then
                if mypy . >> /tmp/build-results/typecheck.txt 2>&1; then
                  TYPECHECK_STATUS="pass"
                else
                  TYPECHECK_STATUS="fail"
                fi
              else
                echo "mypy not found" >> /tmp/build-results/typecheck.txt
              fi
              ;;
            *)
              echo "Typecheck not applicable for ${{ steps.runtime.outputs.runtime }}" >> /tmp/build-results/typecheck.txt
              ;;
          esac
          echo "TYPECHECK_STATUS=$TYPECHECK_STATUS" >> $GITHUB_OUTPUT

          # Combine all results
          cat /tmp/build-results/*.txt > /tmp/build-results/all.txt
          echo "Build: $BUILD_STATUS"
          echo "Tests: $TESTS_STATUS"
          echo "Lint: $LINT_STATUS"
          echo "TypeCheck: $TYPECHECK_STATUS"

      - name: Get issue details
        id: issue
        uses: mkrueger12/claude-parallel/.github/actions/get-issue-details@main
        with:
          issue_number: ${{ needs.review.outputs.issue_number }}
          github_token: ${{ secrets.GH_PAT }}
          event_name: workflow_dispatch

      - name: Fetch verify prompt
        if: ${{ inputs.dry_run != true }}
        run: |
          curl -fsSL "https://raw.githubusercontent.com/${{ inputs.prompts_repo }}/${{ inputs.prompts_ref }}/.github/prompts/verify.md" \
            -o /tmp/verify-template.md

      - name: Run verification
        if: ${{ inputs.dry_run != true }}
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
          APPEND_TRANSCRIPT_TO_PR: ${{ needs.review.outputs.pr_number }}
        run: |
          export PATH="$HOME/.local/bin:$PATH"

          # Build feature request file
          echo "${{ steps.issue.outputs.title }}" > /tmp/feature_request.txt
          echo "" >> /tmp/feature_request.txt
          cat ${{ steps.issue.outputs.body_file }} >> /tmp/feature_request.txt

          # Build check results summary
          BUILD_SUMMARY="| Check | Status |
          |-------|--------|
          | Build | ${{ steps.build_checks.outputs.BUILD_STATUS }} |
          | Tests | ${{ steps.build_checks.outputs.TESTS_STATUS }} |
          | Lint | ${{ steps.build_checks.outputs.LINT_STATUS }} |
          | TypeCheck | ${{ steps.build_checks.outputs.TYPECHECK_STATUS }} |"

          # Substitute template variables using awk
          awk '
            BEGIN {
              while ((getline line < "/tmp/feature_request.txt") > 0) {
                feature = feature (feature ? "\n" : "") line
              }
              while ((getline line < "/tmp/build-results/all.txt") > 0) {
                build_output = build_output (build_output ? "\n" : "") line
              }
            }
            {
              gsub(/\{\{FEATURE_REQUEST\}\}/, feature)
              gsub(/\{\{WINNING_BRANCH\}\}/, "'"${{ needs.review.outputs.winning_branch }}"'")
              gsub(/\{\{PR_NUMBER\}\}/, "'"${{ needs.review.outputs.pr_number }}"'")
              gsub(/\{\{BUILD_STATUS\}\}/, "'"${{ steps.build_checks.outputs.BUILD_STATUS }}"'")
              gsub(/\{\{TESTS_STATUS\}\}/, "'"${{ steps.build_checks.outputs.TESTS_STATUS }}"'")
              gsub(/\{\{LINT_STATUS\}\}/, "'"${{ steps.build_checks.outputs.LINT_STATUS }}"'")
              gsub(/\{\{TYPECHECK_STATUS\}\}/, "'"${{ steps.build_checks.outputs.TYPECHECK_STATUS }}"'")
              gsub(/\{\{BUILD_OUTPUT\}\}/, build_output)
              print
            }
          ' /tmp/verify-template.md > /tmp/verify-prompt.md

          echo "Starting verification..."

          # Generate a UUID for reliable transcript lookup
          VERIFY_SESSION_ID=$(cat /proc/sys/kernel/random/uuid)
          echo "VERIFY_SESSION_ID=$VERIFY_SESSION_ID" >> "$GITHUB_ENV"
          echo "Using session ID: $VERIFY_SESSION_ID"

          claude --print "$(cat /tmp/verify-prompt.md)" \
            --output-format json \
            --model ${{ inputs.claude_model }} \
            --session-id "$VERIFY_SESSION_ID" \
            --dangerously-skip-permissions \
            > verify-result.json 2> verify-error.log || true

          cat verify-result.json

      - name: Post verification transcript to PR
        if: ${{ inputs.dry_run != true }}
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          PR_NUMBER="${{ needs.review.outputs.pr_number }}"
          SESSION_ID="${VERIFY_SESSION_ID:-}"

          if [ -z "$SESSION_ID" ]; then
            echo "No session ID available, skipping transcript post"
            exit 0
          fi

          echo "Looking for transcript with session_id: $SESSION_ID"

          # Find the transcript file - it's stored under ~/.claude/projects/
          TRANSCRIPT_FILE=$(find ~/.claude/projects -name "${SESSION_ID}.jsonl" 2>/dev/null | head -1)

          if [ -z "$TRANSCRIPT_FILE" ] || [ ! -f "$TRANSCRIPT_FILE" ]; then
            echo "Transcript file not found for session $SESSION_ID"
            exit 0
          fi

          echo "Found transcript at: $TRANSCRIPT_FILE"

          # Create formatted transcript
          TRANSCRIPT_MD=$(mktemp)

          cat > "$TRANSCRIPT_MD" << EOF
## Claude Code Verification Transcript

<details>
<summary>Session details</summary>

- **Session ID:** \`$SESSION_ID\`
- **Transcript:** \`$TRANSCRIPT_FILE\`

</details>

---

EOF

          # Process JSONL file and extract conversation
          msg_count=0
          while IFS= read -r line; do
            [ -z "$line" ] && continue

            msg_type=$(echo "$line" | jq -r '.type // empty' 2>/dev/null)

            case "$msg_type" in
              "user")
                # User messages can be plain text or tool results (array)
                content_type=$(echo "$line" | jq -r '.message.content | type' 2>/dev/null)
                if [ "$content_type" = "string" ]; then
                  content=$(echo "$line" | jq -r '.message.content // ""' 2>/dev/null)
                  if [ -n "$content" ]; then
                    msg_count=$((msg_count + 1))
                    {
                      echo "### Prompt"
                      echo ""
                      echo "$content"
                      echo ""
                    } >> "$TRANSCRIPT_MD"
                  fi
                fi
                ;;
              "assistant")
                # Assistant messages have content as array with text/tool_use/thinking elements
                content=$(echo "$line" | jq -r '
                  if .message.content then
                    if (.message.content | type) == "array" then
                      [.message.content[] | select(.type=="text") | .text] | join("\n")
                    else
                      .message.content
                    end
                  else
                    ""
                  end
                ' 2>/dev/null)
                if [ -n "$content" ]; then
                  msg_count=$((msg_count + 1))
                  {
                    echo "### Claude"
                    echo ""
                    echo "$content"
                    echo ""
                    echo "---"
                    echo ""
                  } >> "$TRANSCRIPT_MD"
                fi
                ;;
            esac
          done < "$TRANSCRIPT_FILE"

          # Add footer with message count
          echo "_${msg_count} messages in transcript_" >> "$TRANSCRIPT_MD"

          # Post to PR
          gh pr comment "$PR_NUMBER" --body-file "$TRANSCRIPT_MD" || echo "Failed to post transcript to PR"

          rm -f "$TRANSCRIPT_MD"

      - name: Mock verification (dry run)
        if: ${{ inputs.dry_run == true }}
        run: |
          # Create mock verification result based on build checks
          BUILD="${{ steps.build_checks.outputs.BUILD_STATUS }}"
          TESTS="${{ steps.build_checks.outputs.TESTS_STATUS }}"

          if [ "$BUILD" = "pass" ] || [ "$BUILD" = "skip" ]; then
            VERIFIED="true"
            SUMMARY="Dry run verification passed"
          else
            VERIFIED="false"
            SUMMARY="Dry run verification failed due to build errors"
          fi

          # Create mock result (no leading whitespace - matches Claude output format)
          echo "{\"result\": \"Mock verification complete. {\\\"verified\\\": $VERIFIED, \\\"summary\\\": \\\"$SUMMARY\\\", \\\"issues\\\": []}\"}" > verify-result.json
          cat verify-result.json

      - name: Post verification results to PR
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          # Use pre-computed build results
          BUILD="${{ steps.build_checks.outputs.BUILD_STATUS }}"
          TESTS="${{ steps.build_checks.outputs.TESTS_STATUS }}"
          LINT="${{ steps.build_checks.outputs.LINT_STATUS }}"
          TYPECHECK="${{ steps.build_checks.outputs.TYPECHECK_STATUS }}"

          # Extract the verification result for summary and issues
          RESULT=$(jq -r '.result // .content[0].text // .text // .' verify-result.json)
          VERIFY_JSON=$(echo "$RESULT" | grep -oE '\{[^{}]*"verified"[^{}]*\}' | tail -1)

          if [ -z "$VERIFY_JSON" ]; then
            VERIFIED="false"
            SUMMARY="Could not parse Claude verification output"
            ISSUES=""
          else
            VERIFIED=$(echo "$VERIFY_JSON" | jq -r '.verified // false')
            SUMMARY=$(echo "$VERIFY_JSON" | jq -r '.summary // "No summary"')
            ISSUES=$(echo "$VERIFY_JSON" | jq -r '.issues // [] | .[]' | sed 's/^/- /')
          fi

          # Determine overall status
          if [ "$BUILD" = "fail" ] || [ "$TESTS" = "fail" ]; then
            STATUS=":x: **Verification Failed**"
          elif [ "$VERIFIED" = "true" ]; then
            STATUS=":white_check_mark: **Verified**"
          else
            STATUS=":warning: **Needs Review**"
          fi

          # Format status icons
          format_status() {
            case "$1" in
              pass) echo ":white_check_mark: pass" ;;
              fail) echo ":x: fail" ;;
              skip) echo ":heavy_minus_sign: skip" ;;
              *) echo ":question: $1" ;;
            esac
          }

          COMMENT="## Verification Results

          $STATUS

          | Check | Status |
          |-------|--------|
          | Build | $(format_status "$BUILD") |
          | Tests | $(format_status "$TESTS") |
          | Lint | $(format_status "$LINT") |
          | TypeCheck | $(format_status "$TYPECHECK") |

          ### Summary
          $SUMMARY"

          if [ -n "$ISSUES" ]; then
            COMMENT="$COMMENT

          ### Issues Found
          $ISSUES"
          fi

          gh pr comment "${{ needs.review.outputs.pr_number }}" --body "$COMMENT"

      - name: Upload verification result
        uses: actions/upload-artifact@v4
        with:
          name: verify-result
          path: |
            verify-result.json
            verify-error.log
          retention-days: 7

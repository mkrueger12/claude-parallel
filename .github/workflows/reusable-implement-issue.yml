name: Reusable Claude Implement Linear Issue

on:
  workflow_call:
    inputs:
      linear_issue:
        description: 'Linear issue ID (e.g., ENG-123) or URL'
        required: true
        type: string
      num_implementations:
        description: 'Number of parallel implementations'
        required: false
        type: number
        default: 3
      claude_model:
        description: 'Claude model to use'
        required: false
        type: string
        default: 'claude-opus-4-5-20251101'
      prompts_repo:
        description: 'Repository for prompts and agents'
        required: false
        type: string
        default: 'mkrueger12/claude-parallel'
      prompts_ref:
        description: 'Git ref for prompts repository'
        required: false
        type: string
        default: 'main'
      bot_name:
        description: 'Git author name for commits'
        required: false
        type: string
        default: 'Claude Parallel Bot'
      bot_email:
        description: 'Git author email for commits'
        required: false
        type: string
        default: 'bot@claude-parallel.dev'
      dry_run:
        description: 'Skip Claude, use mock responses'
        required: false
        type: boolean
        default: false
    secrets:
      CLAUDE_CODE_OAUTH_TOKEN:
        required: false
      ANTHROPIC_API_KEY:
        required: false
      LINEAR_API_KEY:
        required: true
      GH_PAT:
        required: true

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.generate.outputs.matrix }}
    steps:
      - name: Validate authentication
        if: ${{ inputs.dry_run != true }}
        run: |
          if [[ -z "${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}" ]] && [[ -z "${{ secrets.ANTHROPIC_API_KEY }}" ]]; then
            echo "Error: At least one authentication method must be provided"
            echo "Please provide either CLAUDE_CODE_OAUTH_TOKEN or ANTHROPIC_API_KEY"
            exit 1
          fi

      - name: Generate matrix
        id: generate
        run: |
          # Generate array [1, 2, ..., num_implementations]
          MATRIX=$(seq 1 ${{ inputs.num_implementations }} | jq -s -c '.')
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT
          echo "Generated matrix: $MATRIX"

  implement:
    needs: generate-matrix
    runs-on: ubuntu-latest
    strategy:
      matrix:
        impl: ${{ fromJSON(needs.generate-matrix.outputs.matrix) }}
      fail-fast: false

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GH_PAT }}

      - name: Create implementation branch
        run: |
          BRANCH="impl-${{ github.run_id }}-${{ matrix.impl }}"
          git checkout -b "$BRANCH"
          echo "BRANCH=$BRANCH" >> $GITHUB_ENV

      - name: Setup Claude CLI
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/setup-claude@main
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}

      - name: Setup OpenCode environment
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/setup-opencode-environment@main

      - name: Fetch custom agents
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/fetch-agents@main
        with:
          repo: ${{ inputs.prompts_repo }}
          ref: ${{ inputs.prompts_ref }}

      - name: Detect runtime
        id: runtime
        uses: mkrueger12/claude-parallel/.github/actions/detect-runtime@main

      - name: Setup runtime and install dependencies
        uses: mkrueger12/claude-parallel/.github/actions/setup-runtime-and-deps@main
        with:
          runtime: ${{ steps.runtime.outputs.runtime }}
          package_manager: ${{ steps.runtime.outputs.package_manager }}

      - name: Fetch implementation prompt
        if: ${{ inputs.dry_run != true }}
        run: |
          curl -fsSL "https://raw.githubusercontent.com/${{ inputs.prompts_repo }}/${{ inputs.prompts_ref }}/prompts/implementation.md" \
            -o /tmp/implementation-template.md

      - name: Run implementation
        if: ${{ inputs.dry_run != true }}
        env:
          LINEAR_API_KEY: ${{ secrets.LINEAR_API_KEY }}
          TURSO_DATABASE_URL: ${{ secrets.TURSO_DATABASE_URL }}
          TURSO_AUTH_TOKEN: ${{ secrets.TURSO_AUTH_TOKEN }}
        run: |
          export PATH="$HOME/.local/bin:$PATH"

          # Substitute LINEAR_ISSUE placeholder with the issue ID/URL
          IMPL_PROMPT=$(sed "s|{{LINEAR_ISSUE}}|${{ inputs.linear_issue }}|g" /tmp/implementation-template.md)

          echo "Starting implementation ${{ matrix.impl }}..."
          echo "Linear issue: ${{ inputs.linear_issue }}"
          echo "Prompt size: $(echo "$IMPL_PROMPT" | wc -c) bytes"

          # Run agent runner and capture exit code
          set +e
          echo "$IMPL_PROMPT" | bun run scripts/claude-agent-runner.ts \
            --cwd "$(pwd)" \
            --model ${{ inputs.claude_model }} \
            --mode implementation \
            > result.json 2> error.log
          RUNNER_EXIT=$?
          set -e

          echo "Agent runner exit code: $RUNNER_EXIT"

          # Check if we got valid output
          if [ -s result.json ] && jq -e . result.json > /dev/null 2>&1; then
            echo "Implementation completed successfully"
          else
            echo "::error::Implementation ${{ matrix.impl }} failed"
            echo "=== Agent runner exit code: $RUNNER_EXIT ==="
            echo "=== result.json contents (first 500 chars): ==="
            head -c 500 result.json 2>/dev/null || echo "(empty or missing)"
            echo ""
            echo "=== error.log contents: ==="
            cat error.log 2>/dev/null || echo "(empty or missing)"
            exit 1
          fi

      - name: Mock implementation (dry run)
        if: ${{ inputs.dry_run == true }}
        run: |
          # Create mock result
          echo '{"result": "Mock implementation ${{ matrix.impl }} completed"}' > result.json

          # Create a mock change to test the workflow
          echo "# Mock Implementation ${{ matrix.impl }}" >> MOCK_CHANGES.md
          echo "" >> MOCK_CHANGES.md
          echo "Issue: ${{ inputs.linear_issue }}" >> MOCK_CHANGES.md
          echo "Run ID: ${{ github.run_id }}" >> MOCK_CHANGES.md
          echo "Timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> MOCK_CHANGES.md

      - name: Commit changes
        run: |
          git config user.name "${{ inputs.bot_name }}"
          git config user.email "${{ inputs.bot_email }}"

          # Add all changes
          git add -A

          if git diff --staged --quiet; then
            echo "No changes to commit"
            echo "HAS_CHANGES=false" >> $GITHUB_ENV
          else
            git commit -m "Implementation ${{ matrix.impl }}: ${{ inputs.linear_issue }}"
            echo "HAS_CHANGES=true" >> $GITHUB_ENV
          fi

      - name: Push branch
        if: env.HAS_CHANGES == 'true'
        run: |
          git push origin "$BRANCH"

      - name: Upload result
        uses: actions/upload-artifact@v4
        with:
          name: impl-${{ matrix.impl }}
          path: |
            result.json
            error.log
          retention-days: 1

  count-successes:
    needs: [generate-matrix, implement]
    if: always() && !cancelled()
    runs-on: ubuntu-latest
    outputs:
      num_successful: ${{ steps.count.outputs.num_successful }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GH_PAT }}

      - name: Count successful implementations
        id: count
        run: |
          SUCCESS_COUNT=0
          for i in $(echo '${{ needs.generate-matrix.outputs.matrix }}' | jq -r '.[]'); do
            BRANCH="impl-${{ github.run_id }}-$i"
            if git fetch origin "$BRANCH" 2>/dev/null; then
              echo "✓ Implementation $i succeeded"
              SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
            else
              echo "✗ Implementation $i failed (branch not found)"
            fi
          done

          echo "num_successful=$SUCCESS_COUNT" >> $GITHUB_OUTPUT
          echo ""
          echo "================================"
          echo "Successfully completed: $SUCCESS_COUNT out of ${{ inputs.num_implementations }} implementations"
          echo "================================"

          if [ "$SUCCESS_COUNT" -lt 2 ]; then
            echo "::error::Only $SUCCESS_COUNT implementation(s) succeeded. At least 2 are required for review."
            exit 1
          fi

  review:
    needs: [generate-matrix, count-successes]
    if: always() && !cancelled() && needs.count-successes.result == 'success'
    runs-on: ubuntu-latest
    outputs:
      winning_branch: ${{ steps.create_pr.outputs.winning_branch }}
      pr_number: ${{ steps.create_pr.outputs.pr_number }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GH_PAT }}

      - name: Download all implementation results
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Fetch implementation branches
        run: |
          mkdir -p worktrees
          for i in $(echo '${{ needs.generate-matrix.outputs.matrix }}' | jq -r '.[]'); do
            BRANCH="impl-${{ github.run_id }}-$i"
            if git fetch origin "$BRANCH" 2>/dev/null; then
              git worktree add "worktrees/impl-$i" "origin/$BRANCH"
              echo "Fetched impl-$i"
            else
              echo "Branch $BRANCH not found (implementation may have failed)"
            fi
          done

      - name: Setup Claude CLI
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/setup-claude@main
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}

      - name: Setup OpenCode environment
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/setup-opencode-environment@main

      - name: Fetch custom agents
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/fetch-agents@main
        with:
          repo: ${{ inputs.prompts_repo }}
          ref: ${{ inputs.prompts_ref }}

      - name: Fetch review prompt
        if: ${{ inputs.dry_run != true }}
        run: |
          curl -fsSL "https://raw.githubusercontent.com/${{ inputs.prompts_repo }}/${{ inputs.prompts_ref }}/prompts/review.md" \
            -o /tmp/review-template.md

      - name: Review implementations
        if: ${{ inputs.dry_run != true }}
        env:
          LINEAR_API_KEY: ${{ secrets.LINEAR_API_KEY }}
          TURSO_DATABASE_URL: ${{ secrets.TURSO_DATABASE_URL }}
          TURSO_AUTH_TOKEN: ${{ secrets.TURSO_AUTH_TOKEN }}
        run: |
          export PATH="$HOME/.local/bin:$PATH"

          # Substitute template variables
          REVIEW_PROMPT=$(sed \
            -e "s|{{LINEAR_ISSUE}}|${{ inputs.linear_issue }}|g" \
            -e "s|{{WORKTREES_DIR}}|worktrees|g" \
            -e "s|{{NUM_IMPLEMENTATIONS}}|${{ inputs.num_implementations }}|g" \
            /tmp/review-template.md)

          echo "Starting review..."
          echo "Linear issue: ${{ inputs.linear_issue }}"

          # Run agent runner in review mode (schema automatically applied)
          echo "$REVIEW_PROMPT" | bun run scripts/claude-agent-runner.ts \
            --cwd "$(pwd)" \
            --model ${{ inputs.claude_model }} \
            --mode review \
            > review-result.json 2> review-error.log || true

          cat review-result.json

      - name: Mock review (dry run)
        if: ${{ inputs.dry_run == true }}
        run: |
          # Pick a random winner (1-num_implementations) for testing
          MAX=${{ inputs.num_implementations }}
          WINNER=$(( (RANDOM % MAX) + 1 ))
          echo "Mock review selecting implementation $WINNER"

          # Agent runner with --mode review always produces structured_output
          echo "{\"type\":\"result\",\"result\":\"\",\"structured_output\":{\"best\":$WINNER,\"reasoning\":\"Dry run mock - selected implementation $WINNER\"}}" > review-result.json

          echo "=== Mock review-result.json: ==="
          cat review-result.json

      - name: Parse review and create PR
        id: create_pr
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          # Extract decision from structured_output (guaranteed by agent runner)
          echo "=== Parsing review result ==="
          cat review-result.json
          echo ""

          DECISION_JSON=$(jq -c '.structured_output' review-result.json 2>/dev/null)

          # Validate the decision exists and has required fields
          if [ -z "$DECISION_JSON" ] || [ "$DECISION_JSON" = "null" ]; then
            echo "::error::No structured_output field in review result"
            echo "Agent runner with --mode review should always produce structured_output"
            exit 1
          fi

          if ! echo "$DECISION_JSON" | jq -e '.best' >/dev/null 2>&1; then
            echo "::error::structured_output missing 'best' field"
            exit 1
          fi

          echo "✓ Successfully extracted decision from structured_output"

          # Parse the extracted JSON
          BEST=$(echo "$DECISION_JSON" | jq -r '.best')
          REASONING=$(echo "$DECISION_JSON" | jq -r '.reasoning // "No reasoning provided"')

          echo "Selected implementation: $BEST"

          WINNING_BRANCH="impl-${{ github.run_id }}-$BEST"
          echo "winning_branch=$WINNING_BRANCH" >> $GITHUB_OUTPUT

          # Create PR
          PR_BODY="## AI-Generated Implementation (Best of ${{ inputs.num_implementations }})

          **Linear Issue:** ${{ inputs.linear_issue }}
          **Selected:** Implementation $BEST

          ### Reasoning
          $REASONING

          ---
          *Generated by Claude Parallel workflow*"

          PR_URL=$(gh pr create \
            --head "$WINNING_BRANCH" \
            --title "Implementation: ${{ inputs.linear_issue }}" \
            --body "$PR_BODY" \
            --draft)

          # Extract PR number from URL
          PR_NUMBER=$(echo "$PR_URL" | grep -oE '[0-9]+$')
          echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
          echo "Created PR #$PR_NUMBER"

      - name: Cleanup losing branches
        if: always() && steps.create_pr.outputs.winning_branch != ''
        run: |
          WINNING="${{ steps.create_pr.outputs.winning_branch }}"
          # Extract impl number (last character after final dash)
          BEST="${WINNING##*-}"

          for i in $(echo '${{ needs.generate-matrix.outputs.matrix }}' | jq -r '.[]'); do
            if [ "$i" != "$BEST" ]; then
              BRANCH="impl-${{ github.run_id }}-$i"
              git push origin --delete "$BRANCH" 2>/dev/null || true
            fi
          done

  verify:
    needs: [count-successes, review]
    if: always() && needs.count-successes.result == 'success' && needs.review.outputs.pr_number != ''
    runs-on: ubuntu-latest

    steps:
      - name: Checkout winning branch
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.review.outputs.winning_branch }}
          fetch-depth: 0
          token: ${{ secrets.GH_PAT }}

      - name: Setup Claude CLI
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/setup-claude@main
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}

      - name: Setup OpenCode environment
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/setup-opencode-environment@main

      - name: Fetch custom agents
        if: ${{ inputs.dry_run != true }}
        uses: mkrueger12/claude-parallel/.github/actions/fetch-agents@main
        with:
          repo: ${{ inputs.prompts_repo }}
          ref: ${{ inputs.prompts_ref }}

      - name: Detect runtime
        id: runtime
        uses: mkrueger12/claude-parallel/.github/actions/detect-runtime@main

      - name: Setup runtime and install dependencies
        uses: mkrueger12/claude-parallel/.github/actions/setup-runtime-and-deps@main
        with:
          runtime: ${{ steps.runtime.outputs.runtime }}
          package_manager: ${{ steps.runtime.outputs.package_manager }}

      - name: Run build checks
        id: build_checks
        uses: mkrueger12/claude-parallel/.github/actions/run-build-checks@main
        with:
          runtime: ${{ steps.runtime.outputs.runtime }}
          package_manager: ${{ steps.runtime.outputs.package_manager }}

      - name: Fetch verify prompt
        if: ${{ inputs.dry_run != true }}
        run: |
          curl -fsSL "https://raw.githubusercontent.com/${{ inputs.prompts_repo }}/${{ inputs.prompts_ref }}/prompts/verify.md" \
            -o /tmp/verify-template.md

      - name: Run verification
        if: ${{ inputs.dry_run != true }}
        env:
          LINEAR_API_KEY: ${{ secrets.LINEAR_API_KEY }}
          TURSO_DATABASE_URL: ${{ secrets.TURSO_DATABASE_URL }}
          TURSO_AUTH_TOKEN: ${{ secrets.TURSO_AUTH_TOKEN }}
        run: |
          export PATH="$HOME/.local/bin:$PATH"

          # Read build output for substitution
          BUILD_OUTPUT=$(cat /tmp/build-results/all.txt)

          # Substitute template variables
          VERIFY_PROMPT=$(sed \
            -e "s|{{LINEAR_ISSUE}}|${{ inputs.linear_issue }}|g" \
            -e "s|{{WINNING_BRANCH}}|${{ needs.review.outputs.winning_branch }}|g" \
            -e "s|{{PR_NUMBER}}|${{ needs.review.outputs.pr_number }}|g" \
            -e "s|{{BUILD_STATUS}}|${{ steps.build_checks.outputs.BUILD_STATUS }}|g" \
            -e "s|{{TESTS_STATUS}}|${{ steps.build_checks.outputs.TESTS_STATUS }}|g" \
            -e "s|{{LINT_STATUS}}|${{ steps.build_checks.outputs.LINT_STATUS }}|g" \
            -e "s|{{TYPECHECK_STATUS}}|${{ steps.build_checks.outputs.TYPECHECK_STATUS }}|g" \
            /tmp/verify-template.md | awk -v build="$BUILD_OUTPUT" '{gsub(/\{\{BUILD_OUTPUT\}\}/, build); print}')

          echo "Starting verification..."
          echo "Linear issue: ${{ inputs.linear_issue }}"

          # Run agent runner in implementation mode
          echo "$VERIFY_PROMPT" | bun run scripts/claude-agent-runner.ts \
            --cwd "$(pwd)" \
            --model ${{ inputs.claude_model }} \
            --mode implementation \
            > verify-result.json 2> verify-error.log || true

          cat verify-result.json

      - name: Mock verification (dry run)
        if: ${{ inputs.dry_run == true }}
        run: |
          # Create mock verification result based on build checks
          BUILD="${{ steps.build_checks.outputs.BUILD_STATUS }}"
          TESTS="${{ steps.build_checks.outputs.TESTS_STATUS }}"

          if [ "$BUILD" = "pass" ] || [ "$BUILD" = "skip" ]; then
            VERIFIED="true"
            SUMMARY="Dry run verification passed"
          else
            VERIFIED="false"
            SUMMARY="Dry run verification failed due to build errors"
          fi

          # Create mock result (no leading whitespace - matches Claude output format)
          echo "{\"result\": \"Mock verification complete. {\\\"verified\\\": $VERIFIED, \\\"summary\\\": \\\"$SUMMARY\\\", \\\"issues\\\": []}\"}" > verify-result.json
          cat verify-result.json

      - name: Post verification results to PR
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          # Use pre-computed build results
          BUILD="${{ steps.build_checks.outputs.BUILD_STATUS }}"
          TESTS="${{ steps.build_checks.outputs.TESTS_STATUS }}"
          LINT="${{ steps.build_checks.outputs.LINT_STATUS }}"
          TYPECHECK="${{ steps.build_checks.outputs.TYPECHECK_STATUS }}"

          # Extract the verification result for summary and issues
          RESULT=$(jq -r '.result // .content[0].text // .text // .' verify-result.json)
          VERIFY_JSON=$(echo "$RESULT" | grep -oE '\{[^{}]*"verified"[^{}]*\}' | tail -1)

          if [ -z "$VERIFY_JSON" ]; then
            VERIFIED="false"
            SUMMARY="Could not parse Claude verification output"
            ISSUES=""
          else
            VERIFIED=$(echo "$VERIFY_JSON" | jq -r '.verified // false')
            SUMMARY=$(echo "$VERIFY_JSON" | jq -r '.summary // "No summary"')
            ISSUES=$(echo "$VERIFY_JSON" | jq -r '.issues // [] | .[]' | sed 's/^/- /')
          fi

          # Determine overall status
          if [ "$BUILD" = "fail" ] || [ "$TESTS" = "fail" ]; then
            STATUS=":x: **Verification Failed**"
          elif [ "$VERIFIED" = "true" ]; then
            STATUS=":white_check_mark: **Verified**"
          else
            STATUS=":warning: **Needs Review**"
          fi

          # Format status icons
          format_status() {
            case "$1" in
              pass) echo ":white_check_mark: pass" ;;
              fail) echo ":x: fail" ;;
              skip) echo ":heavy_minus_sign: skip" ;;
              *) echo ":question: $1" ;;
            esac
          }

          COMMENT="## Verification Results

          $STATUS

          | Check | Status |
          |-------|--------|
          | Build | $(format_status "$BUILD") |
          | Tests | $(format_status "$TESTS") |
          | Lint | $(format_status "$LINT") |
          | TypeCheck | $(format_status "$TYPECHECK") |

          ### Summary
          $SUMMARY"

          if [ -n "$ISSUES" ]; then
            COMMENT="$COMMENT

          ### Issues Found
          $ISSUES"
          fi

          gh pr comment "${{ needs.review.outputs.pr_number }}" --body "$COMMENT"

      - name: Upload verification result
        uses: actions/upload-artifact@v4
        with:
          name: verify-result
          path: |
            verify-result.json
            verify-error.log
          retention-days: 7
